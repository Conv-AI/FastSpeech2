{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00653fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from model import FastSpeech2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "395388ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def explore_ckpt_file(ckpt_path):\n",
    "    try:\n",
    "        # Load the checkpoint data\n",
    "        checkpoint = torch.load(ckpt_path, map_location=torch.device('cpu'))\n",
    "\n",
    "        # List all keys in the checkpoint dictionary (usually contains 'model_state_dict' and more)\n",
    "        print(\"Keys in the checkpoint dictionary:\\n\")\n",
    "        for key in checkpoint.keys():\n",
    "            print(key)\n",
    "\n",
    "        # Access the model's state_dict (modify 'model_state_dict' if different key)\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "            # List all keys in the state_dict (these are the model's parameter names)\n",
    "            print(\"\\nKeys in the model's state_dict:\\n\")\n",
    "            for key in state_dict.keys():\n",
    "                print(key)\n",
    "\n",
    "            # Access specific parameters (you can modify these to explore the data)\n",
    "            print(\"\\nExample: Accessing specific parameters:\\n\")\n",
    "            parameter_name = \"your_parameter_name_here\"  # Change this to a specific parameter name\n",
    "            if parameter_name in state_dict:\n",
    "                parameter = state_dict[parameter_name]\n",
    "                print(f\"Parameter: {parameter_name}\")\n",
    "                print(f\"Shape: {parameter.shape}\")\n",
    "                print(f\"Data: {parameter}\")\n",
    "            else:\n",
    "                print(f\"Parameter {parameter_name} not found in the state_dict.\")\n",
    "        else:\n",
    "            print(\"The 'model_state_dict' key not found in the checkpoint.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    # Replace 'path/to/your/checkpoint.ckpt' with the actual path to your .ckpt file\n",
    "ckpt_file_path = './NovaEmo.pth'\n",
    "#explore_ckpt_file(ckpt_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98d57093",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(ckpt_file_path, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a921fc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "model_config = yaml.load(open('./config/Nova/model.yaml',\n",
    "                              \"r\"), Loader=yaml.FullLoader)\n",
    "preprocess_config = yaml.load(open('./config/Nova/preprocess.yaml',\n",
    "                              \"r\"), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17b82b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eba9ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f3d79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = FastSpeech2(model_config=model_config, preprocess_config=preprocess_config)\n",
    "# #ckpt_file_path = '/workspace/nemo/vol/FastSpeech2/output/ckpt/RAVDESS/800000.pth.tar'\n",
    "# # checkpoint = torch.load(ckpt_file_path, map_location=torch.device('cuda'))\n",
    "# checkpoint = torch.load(ckpt_file_path, map_location=torch.device('cpu'))\n",
    "# fp.load_state_dict(checkpoint['model'])\n",
    "# fp = fp.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2267943",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_speakers = checkpoint['model']['speaker_emb.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfb6ff54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2324, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_speakers.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a002cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_tensor = torch.randn(13, 512)\n",
    "speaker_tensor = torch.randn(210, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1e2ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_emotions = checkpoint['model']['emotion_emb.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98e29195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_emotions.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b53d89ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_speakers = speaker_tensor\n",
    "new_emotions = torch.cat((old_emotions, emotion_tensor), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbc5c496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_speakers.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27936def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26, 512])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_emotions.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84ef9bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint['model']['speaker_emb.weight'] =  speaker_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddb2fce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint['model']['emotion_emb.weight'] = emotion_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318a63da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75009e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = FastSpeech2(model_config=model_config, preprocess_config=preprocess_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e13077f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfc624cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(checkpoint, 'NovaEmo.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "547a7fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker_emb.weight True\n"
     ]
    }
   ],
   "source": [
    "for name, param in fp.named_parameters():\n",
    "    if 'speaker' in name:\n",
    "        print(name, param.requires_grad)\n",
    "        continue\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59bbdb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.position_enc False\n",
      "encoder.src_word_emb.weight True\n",
      "encoder.layer_stack.0.slf_attn.w_qs.weight True\n",
      "encoder.layer_stack.0.slf_attn.w_qs.bias True\n",
      "encoder.layer_stack.0.slf_attn.w_ks.weight True\n",
      "encoder.layer_stack.0.slf_attn.w_ks.bias True\n",
      "encoder.layer_stack.0.slf_attn.w_vs.weight True\n",
      "encoder.layer_stack.0.slf_attn.w_vs.bias True\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.weight True\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.bias True\n",
      "encoder.layer_stack.0.slf_attn.fc.weight True\n",
      "encoder.layer_stack.0.slf_attn.fc.bias True\n",
      "encoder.layer_stack.0.pos_ffn.w_1.weight True\n",
      "encoder.layer_stack.0.pos_ffn.w_1.bias True\n",
      "encoder.layer_stack.0.pos_ffn.w_2.weight True\n",
      "encoder.layer_stack.0.pos_ffn.w_2.bias True\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.weight True\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.bias True\n",
      "encoder.layer_stack.1.slf_attn.w_qs.weight True\n",
      "encoder.layer_stack.1.slf_attn.w_qs.bias True\n",
      "encoder.layer_stack.1.slf_attn.w_ks.weight True\n",
      "encoder.layer_stack.1.slf_attn.w_ks.bias True\n",
      "encoder.layer_stack.1.slf_attn.w_vs.weight True\n",
      "encoder.layer_stack.1.slf_attn.w_vs.bias True\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.weight True\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.bias True\n",
      "encoder.layer_stack.1.slf_attn.fc.weight True\n",
      "encoder.layer_stack.1.slf_attn.fc.bias True\n",
      "encoder.layer_stack.1.pos_ffn.w_1.weight True\n",
      "encoder.layer_stack.1.pos_ffn.w_1.bias True\n",
      "encoder.layer_stack.1.pos_ffn.w_2.weight True\n",
      "encoder.layer_stack.1.pos_ffn.w_2.bias True\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.weight True\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.bias True\n",
      "encoder.layer_stack.2.slf_attn.w_qs.weight True\n",
      "encoder.layer_stack.2.slf_attn.w_qs.bias True\n",
      "encoder.layer_stack.2.slf_attn.w_ks.weight True\n",
      "encoder.layer_stack.2.slf_attn.w_ks.bias True\n",
      "encoder.layer_stack.2.slf_attn.w_vs.weight True\n",
      "encoder.layer_stack.2.slf_attn.w_vs.bias True\n",
      "encoder.layer_stack.2.slf_attn.layer_norm.weight True\n",
      "encoder.layer_stack.2.slf_attn.layer_norm.bias True\n",
      "encoder.layer_stack.2.slf_attn.fc.weight True\n",
      "encoder.layer_stack.2.slf_attn.fc.bias True\n",
      "encoder.layer_stack.2.pos_ffn.w_1.weight True\n",
      "encoder.layer_stack.2.pos_ffn.w_1.bias True\n",
      "encoder.layer_stack.2.pos_ffn.w_2.weight True\n",
      "encoder.layer_stack.2.pos_ffn.w_2.bias True\n",
      "encoder.layer_stack.2.pos_ffn.layer_norm.weight True\n",
      "encoder.layer_stack.2.pos_ffn.layer_norm.bias True\n",
      "encoder.layer_stack.3.slf_attn.w_qs.weight True\n",
      "encoder.layer_stack.3.slf_attn.w_qs.bias True\n",
      "encoder.layer_stack.3.slf_attn.w_ks.weight True\n",
      "encoder.layer_stack.3.slf_attn.w_ks.bias True\n",
      "encoder.layer_stack.3.slf_attn.w_vs.weight True\n",
      "encoder.layer_stack.3.slf_attn.w_vs.bias True\n",
      "encoder.layer_stack.3.slf_attn.layer_norm.weight True\n",
      "encoder.layer_stack.3.slf_attn.layer_norm.bias True\n",
      "encoder.layer_stack.3.slf_attn.fc.weight True\n",
      "encoder.layer_stack.3.slf_attn.fc.bias True\n",
      "encoder.layer_stack.3.pos_ffn.w_1.weight True\n",
      "encoder.layer_stack.3.pos_ffn.w_1.bias True\n",
      "encoder.layer_stack.3.pos_ffn.w_2.weight True\n",
      "encoder.layer_stack.3.pos_ffn.w_2.bias True\n",
      "encoder.layer_stack.3.pos_ffn.layer_norm.weight True\n",
      "encoder.layer_stack.3.pos_ffn.layer_norm.bias True\n",
      "encoder.layer_stack.4.slf_attn.w_qs.weight True\n",
      "encoder.layer_stack.4.slf_attn.w_qs.bias True\n",
      "encoder.layer_stack.4.slf_attn.w_ks.weight True\n",
      "encoder.layer_stack.4.slf_attn.w_ks.bias True\n",
      "encoder.layer_stack.4.slf_attn.w_vs.weight True\n",
      "encoder.layer_stack.4.slf_attn.w_vs.bias True\n",
      "encoder.layer_stack.4.slf_attn.layer_norm.weight True\n",
      "encoder.layer_stack.4.slf_attn.layer_norm.bias True\n",
      "encoder.layer_stack.4.slf_attn.fc.weight True\n",
      "encoder.layer_stack.4.slf_attn.fc.bias True\n",
      "encoder.layer_stack.4.pos_ffn.w_1.weight True\n",
      "encoder.layer_stack.4.pos_ffn.w_1.bias True\n",
      "encoder.layer_stack.4.pos_ffn.w_2.weight True\n",
      "encoder.layer_stack.4.pos_ffn.w_2.bias True\n",
      "encoder.layer_stack.4.pos_ffn.layer_norm.weight True\n",
      "encoder.layer_stack.4.pos_ffn.layer_norm.bias True\n",
      "encoder.layer_stack.5.slf_attn.w_qs.weight True\n",
      "encoder.layer_stack.5.slf_attn.w_qs.bias True\n",
      "encoder.layer_stack.5.slf_attn.w_ks.weight True\n",
      "encoder.layer_stack.5.slf_attn.w_ks.bias True\n",
      "encoder.layer_stack.5.slf_attn.w_vs.weight True\n",
      "encoder.layer_stack.5.slf_attn.w_vs.bias True\n",
      "encoder.layer_stack.5.slf_attn.layer_norm.weight True\n",
      "encoder.layer_stack.5.slf_attn.layer_norm.bias True\n",
      "encoder.layer_stack.5.slf_attn.fc.weight True\n",
      "encoder.layer_stack.5.slf_attn.fc.bias True\n",
      "encoder.layer_stack.5.pos_ffn.w_1.weight True\n",
      "encoder.layer_stack.5.pos_ffn.w_1.bias True\n",
      "encoder.layer_stack.5.pos_ffn.w_2.weight True\n",
      "encoder.layer_stack.5.pos_ffn.w_2.bias True\n",
      "encoder.layer_stack.5.pos_ffn.layer_norm.weight True\n",
      "encoder.layer_stack.5.pos_ffn.layer_norm.bias True\n",
      "variance_adaptor.pitch_bins False\n",
      "variance_adaptor.energy_bins False\n",
      "variance_adaptor.duration_predictor.conv_layer.conv1d_1.conv.weight True\n",
      "variance_adaptor.duration_predictor.conv_layer.conv1d_1.conv.bias True\n",
      "variance_adaptor.duration_predictor.conv_layer.layer_norm_1.weight True\n",
      "variance_adaptor.duration_predictor.conv_layer.layer_norm_1.bias True\n",
      "variance_adaptor.duration_predictor.conv_layer.conv1d_2.conv.weight True\n",
      "variance_adaptor.duration_predictor.conv_layer.conv1d_2.conv.bias True\n",
      "variance_adaptor.duration_predictor.conv_layer.layer_norm_2.weight True\n",
      "variance_adaptor.duration_predictor.conv_layer.layer_norm_2.bias True\n",
      "variance_adaptor.duration_predictor.linear_layer.weight True\n",
      "variance_adaptor.duration_predictor.linear_layer.bias True\n",
      "variance_adaptor.pitch_predictor.conv_layer.conv1d_1.conv.weight True\n",
      "variance_adaptor.pitch_predictor.conv_layer.conv1d_1.conv.bias True\n",
      "variance_adaptor.pitch_predictor.conv_layer.layer_norm_1.weight True\n",
      "variance_adaptor.pitch_predictor.conv_layer.layer_norm_1.bias True\n",
      "variance_adaptor.pitch_predictor.conv_layer.conv1d_2.conv.weight True\n",
      "variance_adaptor.pitch_predictor.conv_layer.conv1d_2.conv.bias True\n",
      "variance_adaptor.pitch_predictor.conv_layer.layer_norm_2.weight True\n",
      "variance_adaptor.pitch_predictor.conv_layer.layer_norm_2.bias True\n",
      "variance_adaptor.pitch_predictor.linear_layer.weight True\n",
      "variance_adaptor.pitch_predictor.linear_layer.bias True\n",
      "variance_adaptor.energy_predictor.conv_layer.conv1d_1.conv.weight True\n",
      "variance_adaptor.energy_predictor.conv_layer.conv1d_1.conv.bias True\n",
      "variance_adaptor.energy_predictor.conv_layer.layer_norm_1.weight True\n",
      "variance_adaptor.energy_predictor.conv_layer.layer_norm_1.bias True\n",
      "variance_adaptor.energy_predictor.conv_layer.conv1d_2.conv.weight True\n",
      "variance_adaptor.energy_predictor.conv_layer.conv1d_2.conv.bias True\n",
      "variance_adaptor.energy_predictor.conv_layer.layer_norm_2.weight True\n",
      "variance_adaptor.energy_predictor.conv_layer.layer_norm_2.bias True\n",
      "variance_adaptor.energy_predictor.linear_layer.weight True\n",
      "variance_adaptor.energy_predictor.linear_layer.bias True\n",
      "variance_adaptor.pitch_embedding.weight True\n",
      "variance_adaptor.energy_embedding.weight True\n",
      "decoder.position_enc False\n",
      "decoder.layer_stack.0.slf_attn.w_qs.weight True\n",
      "decoder.layer_stack.0.slf_attn.w_qs.bias True\n",
      "decoder.layer_stack.0.slf_attn.w_ks.weight True\n",
      "decoder.layer_stack.0.slf_attn.w_ks.bias True\n",
      "decoder.layer_stack.0.slf_attn.w_vs.weight True\n",
      "decoder.layer_stack.0.slf_attn.w_vs.bias True\n",
      "decoder.layer_stack.0.slf_attn.layer_norm.weight True\n",
      "decoder.layer_stack.0.slf_attn.layer_norm.bias True\n",
      "decoder.layer_stack.0.slf_attn.fc.weight True\n",
      "decoder.layer_stack.0.slf_attn.fc.bias True\n",
      "decoder.layer_stack.0.pos_ffn.w_1.weight True\n",
      "decoder.layer_stack.0.pos_ffn.w_1.bias True\n",
      "decoder.layer_stack.0.pos_ffn.w_2.weight True\n",
      "decoder.layer_stack.0.pos_ffn.w_2.bias True\n",
      "decoder.layer_stack.0.pos_ffn.layer_norm.weight True\n",
      "decoder.layer_stack.0.pos_ffn.layer_norm.bias True\n",
      "decoder.layer_stack.1.slf_attn.w_qs.weight True\n",
      "decoder.layer_stack.1.slf_attn.w_qs.bias True\n",
      "decoder.layer_stack.1.slf_attn.w_ks.weight True\n",
      "decoder.layer_stack.1.slf_attn.w_ks.bias True\n",
      "decoder.layer_stack.1.slf_attn.w_vs.weight True\n",
      "decoder.layer_stack.1.slf_attn.w_vs.bias True\n",
      "decoder.layer_stack.1.slf_attn.layer_norm.weight True\n",
      "decoder.layer_stack.1.slf_attn.layer_norm.bias True\n",
      "decoder.layer_stack.1.slf_attn.fc.weight True\n",
      "decoder.layer_stack.1.slf_attn.fc.bias True\n",
      "decoder.layer_stack.1.pos_ffn.w_1.weight True\n",
      "decoder.layer_stack.1.pos_ffn.w_1.bias True\n",
      "decoder.layer_stack.1.pos_ffn.w_2.weight True\n",
      "decoder.layer_stack.1.pos_ffn.w_2.bias True\n",
      "decoder.layer_stack.1.pos_ffn.layer_norm.weight True\n",
      "decoder.layer_stack.1.pos_ffn.layer_norm.bias True\n",
      "decoder.layer_stack.2.slf_attn.w_qs.weight True\n",
      "decoder.layer_stack.2.slf_attn.w_qs.bias True\n",
      "decoder.layer_stack.2.slf_attn.w_ks.weight True\n",
      "decoder.layer_stack.2.slf_attn.w_ks.bias True\n",
      "decoder.layer_stack.2.slf_attn.w_vs.weight True\n",
      "decoder.layer_stack.2.slf_attn.w_vs.bias True\n",
      "decoder.layer_stack.2.slf_attn.layer_norm.weight True\n",
      "decoder.layer_stack.2.slf_attn.layer_norm.bias True\n",
      "decoder.layer_stack.2.slf_attn.fc.weight True\n",
      "decoder.layer_stack.2.slf_attn.fc.bias True\n",
      "decoder.layer_stack.2.pos_ffn.w_1.weight True\n",
      "decoder.layer_stack.2.pos_ffn.w_1.bias True\n",
      "decoder.layer_stack.2.pos_ffn.w_2.weight True\n",
      "decoder.layer_stack.2.pos_ffn.w_2.bias True\n",
      "decoder.layer_stack.2.pos_ffn.layer_norm.weight True\n",
      "decoder.layer_stack.2.pos_ffn.layer_norm.bias True\n",
      "decoder.layer_stack.3.slf_attn.w_qs.weight True\n",
      "decoder.layer_stack.3.slf_attn.w_qs.bias True\n",
      "decoder.layer_stack.3.slf_attn.w_ks.weight True\n",
      "decoder.layer_stack.3.slf_attn.w_ks.bias True\n",
      "decoder.layer_stack.3.slf_attn.w_vs.weight True\n",
      "decoder.layer_stack.3.slf_attn.w_vs.bias True\n",
      "decoder.layer_stack.3.slf_attn.layer_norm.weight True\n",
      "decoder.layer_stack.3.slf_attn.layer_norm.bias True\n",
      "decoder.layer_stack.3.slf_attn.fc.weight True\n",
      "decoder.layer_stack.3.slf_attn.fc.bias True\n",
      "decoder.layer_stack.3.pos_ffn.w_1.weight True\n",
      "decoder.layer_stack.3.pos_ffn.w_1.bias True\n",
      "decoder.layer_stack.3.pos_ffn.w_2.weight True\n",
      "decoder.layer_stack.3.pos_ffn.w_2.bias True\n",
      "decoder.layer_stack.3.pos_ffn.layer_norm.weight True\n",
      "decoder.layer_stack.3.pos_ffn.layer_norm.bias True\n",
      "decoder.layer_stack.4.slf_attn.w_qs.weight True\n",
      "decoder.layer_stack.4.slf_attn.w_qs.bias True\n",
      "decoder.layer_stack.4.slf_attn.w_ks.weight True\n",
      "decoder.layer_stack.4.slf_attn.w_ks.bias True\n",
      "decoder.layer_stack.4.slf_attn.w_vs.weight True\n",
      "decoder.layer_stack.4.slf_attn.w_vs.bias True\n",
      "decoder.layer_stack.4.slf_attn.layer_norm.weight True\n",
      "decoder.layer_stack.4.slf_attn.layer_norm.bias True\n",
      "decoder.layer_stack.4.slf_attn.fc.weight True\n",
      "decoder.layer_stack.4.slf_attn.fc.bias True\n",
      "decoder.layer_stack.4.pos_ffn.w_1.weight True\n",
      "decoder.layer_stack.4.pos_ffn.w_1.bias True\n",
      "decoder.layer_stack.4.pos_ffn.w_2.weight True\n",
      "decoder.layer_stack.4.pos_ffn.w_2.bias True\n",
      "decoder.layer_stack.4.pos_ffn.layer_norm.weight True\n",
      "decoder.layer_stack.4.pos_ffn.layer_norm.bias True\n",
      "decoder.layer_stack.5.slf_attn.w_qs.weight True\n",
      "decoder.layer_stack.5.slf_attn.w_qs.bias True\n",
      "decoder.layer_stack.5.slf_attn.w_ks.weight True\n",
      "decoder.layer_stack.5.slf_attn.w_ks.bias True\n",
      "decoder.layer_stack.5.slf_attn.w_vs.weight True\n",
      "decoder.layer_stack.5.slf_attn.w_vs.bias True\n",
      "decoder.layer_stack.5.slf_attn.layer_norm.weight True\n",
      "decoder.layer_stack.5.slf_attn.layer_norm.bias True\n",
      "decoder.layer_stack.5.slf_attn.fc.weight True\n",
      "decoder.layer_stack.5.slf_attn.fc.bias True\n",
      "decoder.layer_stack.5.pos_ffn.w_1.weight True\n",
      "decoder.layer_stack.5.pos_ffn.w_1.bias True\n",
      "decoder.layer_stack.5.pos_ffn.w_2.weight True\n",
      "decoder.layer_stack.5.pos_ffn.w_2.bias True\n",
      "decoder.layer_stack.5.pos_ffn.layer_norm.weight True\n",
      "decoder.layer_stack.5.pos_ffn.layer_norm.bias True\n",
      "decoder.layer_stack.6.slf_attn.w_qs.weight True\n",
      "decoder.layer_stack.6.slf_attn.w_qs.bias True\n",
      "decoder.layer_stack.6.slf_attn.w_ks.weight True\n",
      "decoder.layer_stack.6.slf_attn.w_ks.bias True\n",
      "decoder.layer_stack.6.slf_attn.w_vs.weight True\n",
      "decoder.layer_stack.6.slf_attn.w_vs.bias True\n",
      "decoder.layer_stack.6.slf_attn.layer_norm.weight True\n",
      "decoder.layer_stack.6.slf_attn.layer_norm.bias True\n",
      "decoder.layer_stack.6.slf_attn.fc.weight True\n",
      "decoder.layer_stack.6.slf_attn.fc.bias True\n",
      "decoder.layer_stack.6.pos_ffn.w_1.weight True\n",
      "decoder.layer_stack.6.pos_ffn.w_1.bias True\n",
      "decoder.layer_stack.6.pos_ffn.w_2.weight True\n",
      "decoder.layer_stack.6.pos_ffn.w_2.bias True\n",
      "decoder.layer_stack.6.pos_ffn.layer_norm.weight True\n",
      "decoder.layer_stack.6.pos_ffn.layer_norm.bias True\n",
      "decoder.layer_stack.7.slf_attn.w_qs.weight True\n",
      "decoder.layer_stack.7.slf_attn.w_qs.bias True\n",
      "decoder.layer_stack.7.slf_attn.w_ks.weight True\n",
      "decoder.layer_stack.7.slf_attn.w_ks.bias True\n",
      "decoder.layer_stack.7.slf_attn.w_vs.weight True\n",
      "decoder.layer_stack.7.slf_attn.w_vs.bias True\n",
      "decoder.layer_stack.7.slf_attn.layer_norm.weight True\n",
      "decoder.layer_stack.7.slf_attn.layer_norm.bias True\n",
      "decoder.layer_stack.7.slf_attn.fc.weight True\n",
      "decoder.layer_stack.7.slf_attn.fc.bias True\n",
      "decoder.layer_stack.7.pos_ffn.w_1.weight True\n",
      "decoder.layer_stack.7.pos_ffn.w_1.bias True\n",
      "decoder.layer_stack.7.pos_ffn.w_2.weight True\n",
      "decoder.layer_stack.7.pos_ffn.w_2.bias True\n",
      "decoder.layer_stack.7.pos_ffn.layer_norm.weight True\n",
      "decoder.layer_stack.7.pos_ffn.layer_norm.bias True\n",
      "mel_linear.weight True\n",
      "mel_linear.bias True\n",
      "postnet.convolutions.0.0.conv.weight True\n",
      "postnet.convolutions.0.0.conv.bias True\n",
      "postnet.convolutions.0.1.weight True\n",
      "postnet.convolutions.0.1.bias True\n",
      "postnet.convolutions.1.0.conv.weight True\n",
      "postnet.convolutions.1.0.conv.bias True\n",
      "postnet.convolutions.1.1.weight True\n",
      "postnet.convolutions.1.1.bias True\n",
      "postnet.convolutions.2.0.conv.weight True\n",
      "postnet.convolutions.2.0.conv.bias True\n",
      "postnet.convolutions.2.1.weight True\n",
      "postnet.convolutions.2.1.bias True\n",
      "postnet.convolutions.3.0.conv.weight True\n",
      "postnet.convolutions.3.0.conv.bias True\n",
      "postnet.convolutions.3.1.weight True\n",
      "postnet.convolutions.3.1.bias True\n",
      "postnet.convolutions.4.0.conv.weight True\n",
      "postnet.convolutions.4.0.conv.bias True\n",
      "postnet.convolutions.4.1.weight True\n",
      "postnet.convolutions.4.1.bias True\n",
      "speaker_emb.weight True\n",
      "emotion_emb.weight True\n"
     ]
    }
   ],
   "source": [
    "for name, param in fp.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3d81512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0625"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256 ** -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bc4442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
