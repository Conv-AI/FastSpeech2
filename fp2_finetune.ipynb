{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "700bef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from model import FastSpeech2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66c64d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def explore_ckpt_file(ckpt_path):\n",
    "    try:\n",
    "        # Load the checkpoint data\n",
    "        checkpoint = torch.load(ckpt_path, map_location=torch.device('cpu'))\n",
    "\n",
    "        # List all keys in the checkpoint dictionary (usually contains 'model_state_dict' and more)\n",
    "        print(\"Keys in the checkpoint dictionary:\\n\")\n",
    "        for key in checkpoint.keys():\n",
    "            print(key)\n",
    "\n",
    "        # Access the model's state_dict (modify 'model_state_dict' if different key)\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "            # List all keys in the state_dict (these are the model's parameter names)\n",
    "            print(\"\\nKeys in the model's state_dict:\\n\")\n",
    "            for key in state_dict.keys():\n",
    "                print(key)\n",
    "\n",
    "            # Access specific parameters (you can modify these to explore the data)\n",
    "            print(\"\\nExample: Accessing specific parameters:\\n\")\n",
    "            parameter_name = \"your_parameter_name_here\"  # Change this to a specific parameter name\n",
    "            if parameter_name in state_dict:\n",
    "                parameter = state_dict[parameter_name]\n",
    "                print(f\"Parameter: {parameter_name}\")\n",
    "                print(f\"Shape: {parameter.shape}\")\n",
    "                print(f\"Data: {parameter}\")\n",
    "            else:\n",
    "                print(f\"Parameter {parameter_name} not found in the state_dict.\")\n",
    "        else:\n",
    "            print(\"The 'model_state_dict' key not found in the checkpoint.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    # Replace 'path/to/your/checkpoint.ckpt' with the actual path to your .ckpt file\n",
    "ckpt_file_path = '/workspace/nemo/vol/FastSpeech2/output/ckpt/RAVDESS/800000.pth.tar'\n",
    "#explore_ckpt_file(ckpt_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad172702",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(ckpt_file_path, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de74d402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "model_config = yaml.load(open('/workspace/nemo/vol/FastSpeech2/config/RAVDESS/model.yaml',\n",
    "                              \"r\"), Loader=yaml.FullLoader)\n",
    "preprocess_config = yaml.load(open('/workspace/nemo/vol/FastSpeech2/config/RAVDESS/preprocess.yaml',\n",
    "                              \"r\"), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78d88f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = FastSpeech2(model_config=model_config, preprocess_config=preprocess_config)\n",
    "ckpt_file_path = '/workspace/nemo/vol/FastSpeech2/output/ckpt/RAVDESS/800000.pth.tar'\n",
    "checkpoint = torch.load(ckpt_file_path, map_location=torch.device('cuda'))\n",
    "fp.load_state_dict(checkpoint['model'])\n",
    "fp = fp.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50408e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FastSpeech2(\n",
       "  (encoder): Encoder(\n",
       "    (src_word_emb): Embedding(361, 256, padding_idx=0)\n",
       "    (layer_stack): ModuleList(\n",
       "      (0-3): 4 x FFTBlock(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (w_ks): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (w_vs): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (softmax): Softmax(dim=2)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Conv1d(256, 1024, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "          (w_2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (variance_adaptor): VarianceAdaptor(\n",
       "    (duration_predictor): VariancePredictor(\n",
       "      (conv_layer): Sequential(\n",
       "        (conv1d_1): Conv(\n",
       "          (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "        (relu_1): ReLU()\n",
       "        (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_1): Dropout(p=0.5, inplace=False)\n",
       "        (conv1d_2): Conv(\n",
       "          (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "        (relu_2): ReLU()\n",
       "        (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "    (length_regulator): LengthRegulator()\n",
       "    (pitch_predictor): VariancePredictor(\n",
       "      (conv_layer): Sequential(\n",
       "        (conv1d_1): Conv(\n",
       "          (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "        (relu_1): ReLU()\n",
       "        (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_1): Dropout(p=0.5, inplace=False)\n",
       "        (conv1d_2): Conv(\n",
       "          (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "        (relu_2): ReLU()\n",
       "        (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "    (energy_predictor): VariancePredictor(\n",
       "      (conv_layer): Sequential(\n",
       "        (conv1d_1): Conv(\n",
       "          (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "        (relu_1): ReLU()\n",
       "        (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_1): Dropout(p=0.5, inplace=False)\n",
       "        (conv1d_2): Conv(\n",
       "          (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "        (relu_2): ReLU()\n",
       "        (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "    (pitch_embedding): Embedding(256, 256)\n",
       "    (energy_embedding): Embedding(256, 256)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layer_stack): ModuleList(\n",
       "      (0-5): 6 x FFTBlock(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (w_ks): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (w_vs): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (softmax): Softmax(dim=2)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Conv1d(256, 1024, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "          (w_2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mel_linear): Linear(in_features=256, out_features=80, bias=True)\n",
       "  (postnet): PostNet(\n",
       "    (convolutions): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1-3): 3 x Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 80, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (speaker_emb): Embedding(5, 256)\n",
       "  (emotion_emb): Embedding(6, 256)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df09960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
